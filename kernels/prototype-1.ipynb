{
  "cells": [
    {
      "metadata": {
        "_uuid": "fdfcf96bb48102a696d32138d8d8a1a40f1ac09c"
      },
      "cell_type": "markdown",
      "source": "# Prototype 1"
    },
    {
      "metadata": {
        "_uuid": "655de847e1ea99083567fbefa1474c1bd833a96f"
      },
      "cell_type": "markdown",
      "source": "## Load Data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d64140125989893ceb6f413472faeb695258450"
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport sys",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(os.listdir(\"../input\"))\n\nprint(\"Reading data...\")\n# Any results you write to the current directory are saved as output.\nchunksize = 2**21\ndataset = pd.read_csv(\"../input/train.csv\", dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64}, chunksize=chunksize)\n\ndef update_progress(progress, title=\"\"):\n    print('\\r{0} [{1}] {2}%'.format(title, '#'*int(progress/2)+' '*int(50-progress/2), progress), end='')\n\n\ndfs = []\nloaded_bytes = 0.0\nfor i, chunck in enumerate(dataset):\n    for j, g in chunck.groupby((chunck.time_to_failure.diff() > 0).cumsum()):\n        frags = []\n        for k, h in g.groupby((g.time_to_failure.diff() < -0.0001).cumsum()):\n            frags.append(h)\n            loaded_bytes += float(h.memory_usage(index=True, deep=True).sum())\n        if j == 0 and len(dfs) > 0 and dfs[-1][-1].tail(1).time_to_failure.values[0] >= g.head(1).time_to_failure.values[0]:\n            dfs[-1] += frags\n        else:\n            dfs.append(frags)\n    update_progress(int(100.0 * loaded_bytes / 15099491520.0), \"Earthquake: {0:3d} Fragment: {1:8d} \".format(len(dfs), len(dfs[-1])))",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['test', 'train.csv', 'sample_submission.csv']\nReading data...\nEarthquake:  17 Fragment:     1751  [#####################################            ] 75%%",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "50c2fcc723676f04de62f4538bb910fe3a561f1b"
      },
      "cell_type": "markdown",
      "source": "# Data Visualization"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34d9d6398ea1d5f88a9508f5dcee61b9483f416e"
      },
      "cell_type": "code",
      "source": "last_ave_1 = 0\nlast_ave_2 = 0\nlast_ave_3 = 0\nlast_ave_4 = 0\nlast_ave_5 = 0\nlast_ave_6 = 0\nlast_ave_7 = 0\nlast_ave_8 = 0\nlast_ave_9 = 0\nlast_ave_10 = 0\nlast_ave_11 = 0\nlast_ave_12 = 0\nlast_ave_13 = 0\nlast_ave_14 = 0\nlast_ave_15 = 0\nlast_ave_16 = 0\nlast_ave_17 = 0\nlast_ave_18 = 0\nlast_ave_19 = 0\nlast_ave_20 = 0\nlast_ave_21 = 0\nlast_ave_22 = 0\nlast_ave_23 = 0\nlast_ave_24 = 0\nlast_ave_25 = 0\n\n\nn = 0\nfrag_duration_cum = 0\nfrag_gap_cum = 0\ndiff_ave_cum = 0\nfor frag in dfs:\n    for df in frag:\n        count = len(df.index)\n        head = df.head(1).time_to_failure.values[0]\n        tail = df.tail(1).time_to_failure.values[0]\n        ave = df.time_to_failure.mean()\n        diff_ave = df.tail(4095).time_to_failure.diff().mean()\n        frag_duration = tail-head\n        frag_gap_ave = ave-last_ave_25\n        if frag_gap_ave < 0 and count == 4096:\n            n += 1\n            frag_gap_cum += frag_gap_ave\n            frag_duration_cum += frag_duration\n            diff_ave_cum += diff_ave\n        print(count, frag_duration, frag_gap_ave, frag_gap_ave/diff_ave, diff_ave, end='\\r')\n        last_ave_25 = last_ave_24\n        last_ave_24 = last_ave_23\n        last_ave_23 = last_ave_22\n        last_ave_22 = last_ave_21\n        last_ave_21 = last_ave_20\n        last_ave_20 = last_ave_19\n        last_ave_19 = last_ave_18\n        last_ave_18 = last_ave_17\n        last_ave_17 = last_ave_16\n        last_ave_16 = last_ave_15\n        last_ave_15 = last_ave_14\n        last_ave_14 = last_ave_13\n        last_ave_13 = last_ave_12\n        last_ave_12 = last_ave_11\n        last_ave_11 = last_ave_10\n        last_ave_10 = last_ave_9\n        last_ave_9 = last_ave_8\n        last_ave_8 = last_ave_7\n        last_ave_7 = last_ave_6\n        last_ave_6 = last_ave_5\n        last_ave_5 = last_ave_4\n        last_ave_4 = last_ave_3\n        last_ave_3 = last_ave_2\n        last_ave_2 = last_ave_1\n        last_ave_1 = ave\nfrag_gap_ave = frag_gap_cum/n\nfrag_duration_ave = frag_duration_cum/n\nprint(frag_gap_ave, frag_duration_ave, 25*frag_gap_ave/frag_duration_ave, diff_ave_cum/n)\n# 967,491.030451251 = 4096*236.20386485626256\n# 967,489.195553758 = 4096*236.2034168832417\n# 967,491.030447658 = 4096*236.20386485538532\n# 1,000,133.18541318 = \n#",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\ndfs[1].plot(kind='line',x='time_to_failure',y='acoustic_data', figsize=(100,20))\n\nprint(dfs[0].memory_usage(index=True, deep=True).sum())\nos.listdir(\"../input/test/\")\ntest_file = \"../input/test/\" + os.listdir(\"../input/test/\")[1]\nprint(test_file)\ndataset_test = pd.read_csv(test_file)\ndataset_test.plot(kind='line',y='acoustic_data', figsize=(100,20))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}